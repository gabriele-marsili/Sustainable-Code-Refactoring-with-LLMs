{
  "llama3": {
    "temperature": 0.2,
    "max_tokens": 3000,
    "timeout": 120
  },
  "gpt4": {
    "temperature": 0.1,
    "max_tokens": 4000,
    "timeout": 90
  },
  "gpt4o": {
    "temperature": 0.1,
    "max_tokens": 4000,
    "timeout": 90
  },
  "gemini_flash": {
    "temperature": 0.2,
    "max_tokens": 8000,
    "timeout": 60
  },
  "claude_sonnet": {
    "temperature": 0.1,
    "max_tokens": 4000,
    "timeout": 120
  },
  "claude_sonnet4": {
    "temperature": 0.1,
    "max_tokens": 4000,
    "timeout": 120
  }
}
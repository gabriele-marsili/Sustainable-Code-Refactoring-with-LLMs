{
  "metadata": {
    "elapsed_time_str" : "27h 14m 26s",
    "generation_date": "2025-10-19T19:40:43.392882",
    "source_outlier_report": "/Users/piccoletto/Desktop/Everything/pisa/tesi/Sustainable-Code-Refactoring-with-LLMs/src/metrics/outlier_reports/outliers_report_20251018_160045.json",
    "num_executions": 5,
    "max_workers": 4,
    "dry_run": false,
    "total_clusters_rerun": 182
  },
  "results": {
    "anagram": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 4,
        "by_llm": {
          "claude": 1,
          "gemini": 3
        },
        "by_prompt_version": {
          "v1": 2,
          "v2": 1,
          "v4": 1
        },
        "by_metric": {
          "execution_time_ms": 2,
          "CPU_usage": 2
        },
        "affected_entries": [
          "c_anagram_Exercism (m3g4d1v3r)",
          "go_anagram_Exercism (go_drapala)"
        ]
      }
    },
    "binary_tree_right_side_view": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "binary_tree_right_side_view_132"
        ]
      }
    },
    "calculate_area_of_polygon": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "calculate_area_of_polygon_235"
        ]
      }
    },
    "candy": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "candy_165"
        ]
      }
    },
    "card_games": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "card-games_5"
        ]
      }
    },
    "chaitanas_colossal_coaster": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "chaitanas-colossal-coaster_6"
        ]
      }
    },
    "check_if_two_rectangles_overlap": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "check_if_two_rectangles_overlap_237"
        ]
      }
    },
    "climbing_staircase": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "climbing_staircase_199"
        ]
      }
    },
    "clock": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 1,
        "by_llm": {
          "openAI": 1
        },
        "by_prompt_version": {
          "v2": 1
        },
        "by_metric": {
          "execution_time_ms": 1
        },
        "affected_entries": [
          "c_clock_Exercism (vlzware)"
        ]
      }
    },
    "collatz_conjecture": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "collatz-conjecture_8"
        ]
      }
    },
    "connect": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 18
        },
        "affected_entries": [
          "javascript_connect_exercism-javascript-ThomasZumsteg",
          "javascript_connect_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "container_with_most_water": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 36,
        "by_llm": {
          "openAI": 12,
          "claude": 12,
          "gemini": 12
        },
        "by_prompt_version": {
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 18,
          "RAM_usage": 18
        },
        "affected_entries": [
          "container_with_most_water_133",
          "container_with_most_water_151"
        ]
      }
    },
    "contains_duplicate": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "contains_duplicate_166"
        ]
      }
    },
    "count_consecutive_sums": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "count_consecutive_sums_246"
        ]
      }
    },
    "count_divisibles_in_range": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "count_divisibles_in_range_238"
        ]
      }
    },
    "count_ip_addresses": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "count_ip_addresses_201"
        ]
      }
    },
    "count_positives": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "count_positives_219"
        ]
      }
    },
    "count_triplets_with_sum_k": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 2,
        "by_llm": {
          "claude": 1,
          "openAI": 1
        },
        "by_prompt_version": {
          "v4": 2
        },
        "by_metric": {
          "execution_time_ms": 2
        },
        "affected_entries": [
          "count_triplets_with_sum_k_179"
        ]
      }
    },
    "crypto_square": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 27,
        "by_llm": {
          "openAI": 9,
          "claude": 9,
          "gemini": 9
        },
        "by_prompt_version": {
          "v2": 9,
          "v3": 9,
          "v4": 9
        },
        "by_metric": {
          "execution_time_ms": 27
        },
        "affected_entries": [
          "Java_crypto-square_exercism-java-ThomasZumsteg",
          "Java_crypto-square_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_crypto-square_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "currency_exchange": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "currency-exchange_9"
        ]
      }
    },
    "custom_set": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 18
        },
        "affected_entries": [
          "javascript_custom-set_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_custom-set_exercism-javascript-ThomasZumsteg"
        ]
      }
    },
    "diamond": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 1,
        "by_llm": {
          "claude": 1
        },
        "by_prompt_version": {
          "v4": 1
        },
        "by_metric": {
          "execution_time_ms": 1
        },
        "affected_entries": [
          "c_diamond_Exercism (ThomasZumsteg)"
        ]
      }
    },
    "difference_of_squares": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 5,
        "by_llm": {
          "claude": 2,
          "openAI": 3
        },
        "by_prompt_version": {
          "v1": 1,
          "v2": 2,
          "v3": 1,
          "v4": 1
        },
        "by_metric": {
          "execution_time_ms": 5
        },
        "affected_entries": [
          "c_difference_of_squares_Exercism (ThomasZumsteg)"
        ]
      }
    },
    "dn_dcharacter": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "java_dnd_character_Govanator12"
        ]
      }
    },
    "dnd_character": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "Java_dnd-character_exercism-java-uzilan_robiworks"
        ]
      }
    },
    "encode_and_decode_strings": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "encode_and_decode_strings_134"
        ]
      }
    },
    "etl": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 108,
        "by_llm": {
          "openAI": 36,
          "claude": 36,
          "gemini": 36
        },
        "by_prompt_version": {
          "v1": 27,
          "v2": 27,
          "v3": 27,
          "v4": 27
        },
        "by_metric": {
          "execution_time_ms": 108
        },
        "affected_entries": [
          "javascript_etl_exercism-javascript-ffflorian_ffflorian",
          "javascript_etl_exercism-javascript-irvingbennett_irvingbennett",
          "javascript_etl_exercism-javascript-oguzsh_oguzsh",
          "javascript_etl_exercism-javascript-bearguns_bearguns",
          "javascript_etl_exercism-javascript-programmiri_programmiri",
          "javascript_etl_exercism-javascript-ffflorian",
          "javascript_etl_exercism-javascript-oguzsh",
          "javascript_etl_exercism-javascript-ThomasZumsteg",
          "javascript_etl_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "evaluate_reverse_polish_notation": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "evaluate_reverse_polish_notation_135"
        ]
      }
    },
    "fancy_sequence": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "fancy_sequence_247"
        ]
      }
    },
    "find_busiest_interval": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_busiest_interval_152"
        ]
      }
    },
    "find_el_smaller_left_bigger_right": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "find_el_smaller_left_bigger_right_153"
        ]
      }
    },
    "find_el_where_k_greater_or_equal": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_el_where_k_greater_or_equal_154"
        ]
      }
    },
    "find_element_range_sorted_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_element_range_sorted_array_155"
        ]
      }
    },
    "find_first_missing_positive": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_first_missing_positive_180"
        ]
      }
    },
    "find_min_path": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_min_path_248"
        ]
      }
    },
    "find_missing_number_in_second_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "find_missing_number_in_second_array_181"
        ]
      }
    },
    "find_one_missing_number": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_one_missing_number_156"
        ]
      }
    },
    "find_peak_element": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 1,
        "by_llm": {
          "claude": 1
        },
        "by_prompt_version": {
          "v1": 1
        },
        "by_metric": {
          "execution_time_ms": 1
        },
        "affected_entries": [
          "find_peak_element_157"
        ]
      }
    },
    "find_two_missing_numbers": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_two_missing_numbers_158"
        ]
      }
    },
    "find_unpaired": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "find_unpaired_159"
        ]
      }
    },
    "flatten_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 18
        },
        "affected_entries": [
          "javascript_flatten-array_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_flatten-array_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "flatten_deep_list": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "flatten_deep_list_160"
        ]
      }
    },
    "food_chain": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 60,
        "by_llm": {
          "openAI": 20,
          "claude": 20,
          "gemini": 20
        },
        "by_prompt_version": {
          "v1": 15,
          "v2": 15,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 60
        },
        "affected_entries": [
          "java_food-chain_aaron-contreras",
          "javascript_food-chain_exercism-javascript-ffflorian_ffflorian",
          "javascript_food-chain_exercism-javascript-ffflorian",
          "javascript_food-chain_exercism-javascript-ThomasZumsteg",
          "javascript_food-chain_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "freelancer_rates": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "javascript_freelancer-rates_exercism-javascript-PhymasSC_PhymasSC"
        ]
      }
    },
    "ghost_gobble_arcade_game": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "ghost-gobble-arcade-game_11"
        ]
      }
    },
    "gigasecond": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 54,
        "by_llm": {
          "openAI": 18,
          "claude": 18,
          "gemini": 18
        },
        "by_prompt_version": {
          "v2": 18,
          "v3": 18,
          "v4": 18
        },
        "by_metric": {
          "execution_time_ms": 54
        },
        "affected_entries": [
          "javascript_gigasecond_exercism-javascript-ffflorian_ffflorian",
          "javascript_gigasecond_exercism-javascript-oguzsh_oguzsh",
          "javascript_gigasecond_exercism-javascript-programmiri",
          "javascript_gigasecond_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_gigasecond_exercism-javascript-bearguns_bearguns",
          "javascript_gigasecond_exercism-javascript-programmiri_programmiri"
        ]
      }
    },
    "grade_school": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 72,
        "by_llm": {
          "openAI": 24,
          "claude": 24,
          "gemini": 24
        },
        "by_prompt_version": {
          "v2": 24,
          "v3": 24,
          "v4": 24
        },
        "by_metric": {
          "execution_time_ms": 63,
          "RAM_usage": 9
        },
        "affected_entries": [
          "javascript_grade-school_exercism-javascript-ffflorian",
          "javascript_grade-school_exercism-javascript-ffflorian_ffflorian",
          "javascript_grade-school_exercism-javascript-ThomasZumsteg",
          "javascript_grade-school_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_grade-school_exercism-javascript-irvingbennett_irvingbennett",
          "grade-school_12",
          "javascript_grade-school_exercism-javascript-irvingbennett"
        ]
      }
    },
    "grains": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 72,
        "by_llm": {
          "openAI": 24,
          "claude": 24,
          "gemini": 24
        },
        "by_prompt_version": {
          "v2": 24,
          "v3": 24,
          "v4": 24
        },
        "by_metric": {
          "execution_time_ms": 36,
          "RAM_usage": 27,
          "CPU_usage": 9
        },
        "affected_entries": [
          "java_grains_aaron-contreras",
          "typescript_grains_Exercism-typescript-shybyte_shybyte",
          "c_grains_Exercism (HeitorMP)",
          "grains_13",
          "c_grains_Exercism (m3g4d1v3r)"
        ]
      }
    },
    "guidos_gorgeous_lasagna": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "guidos-gorgeous-lasagna_14"
        ]
      }
    },
    "hamming": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 36,
        "by_llm": {
          "openAI": 12,
          "claude": 12,
          "gemini": 12
        },
        "by_prompt_version": {
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 27,
          "RAM_usage": 9
        },
        "affected_entries": [
          "javascript_hamming_exercism-javascript-programmiri_programmiri",
          "hamming_15",
          "Java_hamming_exercism-java-blogscot_blogscot"
        ]
      }
    },
    "hello_world": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 144,
        "by_llm": {
          "openAI": 48,
          "claude": 48,
          "gemini": 48
        },
        "by_prompt_version": {
          "v1": 36,
          "v2": 36,
          "v3": 36,
          "v4": 36
        },
        "by_metric": {
          "execution_time_ms": 144
        },
        "affected_entries": [
          "Java_hello-world_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_hello-world_exercism-javascript-bearguns",
          "javascript_hello-world_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "Java_hello-world_exercism-java-blogscot",
          "javascript_hello-world_exercism-javascript-oguzsh",
          "javascript_hello-world_exercism-javascript-programmiri_programmiri",
          "javascript_hello-world_exercism-javascript-programmiri",
          "javascript_hello-world_exercism-javascript-bearguns_bearguns",
          "javascript_hello-world_exercism-javascript-ffflorian_ffflorian",
          "Java_hello-world_exercism-java-blogscot_blogscot",
          "Java_hello-world_exercism-java-uzilan_robiworks",
          "javascript_hello-world_exercism-javascript-oguzsh_oguzsh"
        ]
      }
    },
    "hexadecimal": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "javascript_hexadecimal_exercism-javascript-ThomasZumsteg",
          "javascript_hexadecimal_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "high_score_board": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "javascript_high-score-board_exercism-javascript-PhymasSC_PhymasSC"
        ]
      }
    },
    "high_scores": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 48,
        "by_llm": {
          "openAI": 16,
          "claude": 16,
          "gemini": 16
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 36,
          "RAM_usage": 12
        },
        "affected_entries": [
          "javascript_high-scores_exercism-javascript-ffflorian_ffflorian",
          "javascript_high-scores_exercism-javascript-ffflorian",
          "high-scores_16"
        ]
      }
    },
    "house": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "Java_house_Exercism (java_rabestro)"
        ]
      }
    },
    "isbn_verifier": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 84,
        "by_llm": {
          "openAI": 28,
          "claude": 28,
          "gemini": 28
        },
        "by_prompt_version": {
          "v1": 21,
          "v2": 21,
          "v3": 21,
          "v4": 21
        },
        "by_metric": {
          "execution_time_ms": 72,
          "RAM_usage": 12
        },
        "affected_entries": [
          "javascript_isbn-verifier_exercism-javascript-ffflorian_ffflorian",
          "javascript_isbn-verifier_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "isbn-verifier_17",
          "Java_isbn-verifier_exercism-java-blogscot",
          "javascript_isbn-verifier_exercism-javascript-ThomasZumsteg",
          "Java_isbn-verifier_exercism-java-blogscot_blogscot"
        ]
      }
    },
    "isogram": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 72,
        "by_llm": {
          "openAI": 24,
          "claude": 24,
          "gemini": 24
        },
        "by_prompt_version": {
          "v2": 24,
          "v3": 24,
          "v4": 24
        },
        "by_metric": {
          "execution_time_ms": 63,
          "RAM_usage": 9
        },
        "affected_entries": [
          "javascript_isogram_exercism-javascript-ffflorian_ffflorian",
          "Java_isogram_exercism-java-uzilan_robiworks",
          "javascript_isogram_exercism-javascript-ffflorian",
          "isogram_18",
          "javascript_isogram_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "Java_isogram_exercism-java-blogscot_blogscot",
          "javascript_isogram_exercism-javascript-bearguns_bearguns"
        ]
      }
    },
    "jump_game": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "jump_game_161"
        ]
      }
    },
    "kindergarten_garden": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "kindergarten-garden_19"
        ]
      }
    },
    "largest_series_product_calculator": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "java_largest_series_product_aaron-contreras",
          "java_series_aaron-contreras"
        ]
      }
    },
    "lasagna": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "javascript_lasagna_exercism-javascript-PhymasSC_PhymasSC"
        ]
      }
    },
    "lasagna_master": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "javascript_lasagna-master_exercism-javascript-PhymasSC_PhymasSC",
          "javascript_lasagna-master_exercism-javascript-PhymasSC"
        ]
      }
    },
    "letter_combinations": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "letter_combinations_251"
        ]
      }
    },
    "linked_list": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 108,
        "by_llm": {
          "openAI": 36,
          "claude": 36,
          "gemini": 36
        },
        "by_prompt_version": {
          "v1": 27,
          "v2": 27,
          "v3": 27,
          "v4": 27
        },
        "by_metric": {
          "execution_time_ms": 108
        },
        "affected_entries": [
          "javascript_linked-list_exercism-javascript-shyvum",
          "javascript_linked-list_exercism-javascript-ThomasZumsteg",
          "javascript_linked-list_exercism-javascript-PhymasSC_PhymasSC",
          "javascript_linked-list_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_linked-list_exercism-javascript-ffflorian_ffflorian",
          "javascript_linked-list_exercism-javascript-shyvum_shyvum",
          "javascript_linked-list_exercism-javascript-PhymasSC",
          "javascript_linked-list_exercism-javascript-ffflorian",
          "javascript_linked-list_exercism-javascript-irvingbennett_irvingbennett"
        ]
      }
    },
    "linked_list_cycle": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "linked_list_cycle_167"
        ]
      }
    },
    "little_sisters_essay": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "little-sisters-essay_20"
        ]
      }
    },
    "little_sisters_vocab": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "little-sisters-vocab_21"
        ]
      }
    },
    "longest_common_prefix": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "longest_common_prefix_269"
        ]
      }
    },
    "longest_common_subsequence": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "longest_common_subsequence_205"
        ]
      }
    },
    "longest_consecutive_sequence": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "longest_consecutive_sequence_138"
        ]
      }
    },
    "longest_increasing_subarray": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "longest_increasing_subarray_162"
        ]
      }
    },
    "longest_palindromic_substring": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "longest_palindromic_substring_270"
        ]
      }
    },
    "longest_repeating_character_replacement": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "longest_repeating_character_replacement_139"
        ]
      }
    },
    "longest_substring_without_repeating_characters": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 48,
        "by_llm": {
          "openAI": 16,
          "claude": 16,
          "gemini": 16
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 24,
          "RAM_usage": 24
        },
        "affected_entries": [
          "longest_substring_without_repeating_characters_140",
          "longest_substring_without_repeating_characters_224"
        ]
      }
    },
    "lucky_numbers": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "javascript_lucky-numbers_exercism-javascript-PhymasSC_PhymasSC"
        ]
      }
    },
    "luhn": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 42,
        "by_llm": {
          "openAI": 14,
          "claude": 14,
          "gemini": 14
        },
        "by_prompt_version": {
          "v2": 12,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 24,
          "RAM_usage": 9,
          "CPU_usage": 9
        },
        "affected_entries": [
          "javascript_luhn_exercism-javascript-ThomasZumsteg",
          "javascript_luhn_exercism-javascript-ffflorian_ffflorian",
          "luhn_22",
          "javascript_luhn_exercism-javascript-ffflorian"
        ]
      }
    },
    "majority_element": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "majority_element_184"
        ]
      }
    },
    "making_the_grade": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "making-the-grade_23"
        ]
      }
    },
    "markdown": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 27,
        "by_llm": {
          "openAI": 9,
          "claude": 9,
          "gemini": 9
        },
        "by_prompt_version": {
          "v2": 9,
          "v3": 9,
          "v4": 9
        },
        "by_metric": {
          "execution_time_ms": 18,
          "RAM_usage": 9
        },
        "affected_entries": [
          "markdown_24",
          "Java_markdown_exercism-java-shyvum_shyvum"
        ]
      }
    },
    "matrix": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 156,
        "by_llm": {
          "openAI": 52,
          "claude": 52,
          "gemini": 52
        },
        "by_prompt_version": {
          "v1": 39,
          "v2": 39,
          "v3": 39,
          "v4": 39
        },
        "by_metric": {
          "execution_time_ms": 144,
          "RAM_usage": 12
        },
        "affected_entries": [
          "javascript_matrix_exercism-javascript-oguzsh",
          "javascript_matrix_exercism-javascript-irvingbennett",
          "javascript_matrix_exercism-javascript-ffflorian",
          "javascript_matrix_exercism-javascript-ffflorian_ffflorian",
          "javascript_matrix_exercism-javascript-oguzsh_oguzsh",
          "javascript_matrix_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_matrix_exercism-javascript-irvingbennett_irvingbennett",
          "javascript_matrix_exercism-javascript-programmiri",
          "javascript_matrix_exercism-javascript-PhymasSC",
          "javascript_matrix_exercism-javascript-PhymasSC_PhymasSC",
          "matrix_25",
          "javascript_matrix_exercism-javascript-programmiri_programmiri"
        ]
      }
    },
    "maximum_depth_of_binary_tree": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 3,
        "by_llm": {
          "openAI": 1,
          "claude": 1,
          "gemini": 1
        },
        "by_prompt_version": {
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 3
        },
        "affected_entries": [
          "maximum_depth_of_binary_tree_168"
        ]
      }
    },
    "meetup": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "c_meetup_Exercism (vlzware)"
        ]
      }
    },
    "merge_intervals": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "merge_intervals_185"
        ]
      }
    },
    "merge_sorted_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 1,
        "by_llm": {
          "openAI": 1
        },
        "by_prompt_version": {
          "v4": 1
        },
        "by_metric": {
          "CPU_usage": 1
        },
        "affected_entries": [
          "merge_sorted_array_169"
        ]
      }
    },
    "min_cost_coloring": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "min_cost_coloring_210"
        ]
      }
    },
    "min_stack": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "min_stack_141"
        ]
      }
    },
    "min_swaps": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "min_swaps_186"
        ]
      }
    },
    "minesweeper": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 12,
        "by_llm": {
          "openAI": 4,
          "claude": 4,
          "gemini": 4
        },
        "by_prompt_version": {
          "v1": 3,
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 12
        },
        "affected_entries": [
          "javascript_minesweeper_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "minimum_absolute_difference_in_bst": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "minimum_absolute_difference_in_bst_170"
        ]
      }
    },
    "minimum_size_subarray_sum": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "minimum_size_subarray_sum_142"
        ]
      }
    },
    "minimum_window_substring": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "minimum_window_substring_171"
        ]
      }
    },
    "mixed_juices": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 12,
        "by_llm": {
          "openAI": 4,
          "claude": 4,
          "gemini": 4
        },
        "by_prompt_version": {
          "v1": 3,
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 12
        },
        "affected_entries": [
          "javascript_mixed-juices_exercism-javascript-PhymasSC_PhymasSC"
        ]
      }
    },
    "nth_fibonacci_number": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "nth_fibonacci_number_252"
        ]
      }
    },
    "nth_prime": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 45,
        "by_llm": {
          "openAI": 15,
          "claude": 15,
          "gemini": 15
        },
        "by_prompt_version": {
          "v2": 15,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 18,
          "RAM_usage": 27
        },
        "affected_entries": [
          "cpp_nth_prime_Exercism (thefullarcticfox)",
          "cpp_nth_prime_Exercism (johnngugi)",
          "cpp_nth_prime_Exercism (blogscot)"
        ]
      }
    },
    "number_of_islands": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 48,
        "by_llm": {
          "openAI": 16,
          "claude": 16,
          "gemini": 16
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 24,
          "RAM_usage": 24
        },
        "affected_entries": [
          "number_of_islands_143",
          "number_of_islands_253"
        ]
      }
    },
    "ocr_numbers": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "javascript_ocr-numbers_exercism-javascript-ThomasZumsteg",
          "javascript_ocr-numbers_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "octal": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 6,
        "by_llm": {
          "claude": 2,
          "gemini": 3,
          "openAI": 1
        },
        "by_prompt_version": {
          "v2": 2,
          "v3": 2,
          "v4": 2
        },
        "by_metric": {
          "execution_time_ms": 6
        },
        "affected_entries": [
          "javascript_octal_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "odd_sum": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "odd_sum_240"
        ]
      }
    },
    "optical_character_reader": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 12,
        "by_llm": {
          "openAI": 4,
          "claude": 4,
          "gemini": 4
        },
        "by_prompt_version": {
          "v1": 3,
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 12
        },
        "affected_entries": [
          "java_ocr-numbers_stuartnankai"
        ]
      }
    },
    "ordered_digits": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "ordered_digits_213"
        ]
      }
    },
    "ozans_playlist": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "javascript_ozans-playlist_exercism-javascript-PhymasSC_PhymasSC",
          "javascript_ozans-playlist_exercism-javascript-PhymasSC"
        ]
      }
    },
    "palindrome_integer": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "palindrome_integer_254"
        ]
      }
    },
    "pascals_triangle": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 90,
        "by_llm": {
          "openAI": 30,
          "claude": 30,
          "gemini": 30
        },
        "by_prompt_version": {
          "v2": 30,
          "v3": 30,
          "v4": 30
        },
        "by_metric": {
          "execution_time_ms": 90
        },
        "affected_entries": [
          "Java_pascals-triangle_exercism-java-ThomasZumsteg",
          "Java_pascals-triangle_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_pascals-triangle_exercism-javascript-irvingbennett_irvingbennett",
          "javascript_pascals-triangle_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_pascals-triangle_exercism-javascript-ThomasZumsteg",
          "javascript_pascals-triangle_exercism-javascript-irvingbennett",
          "javascript_pascals-triangle_exercism-javascript-ffflorian",
          "javascript_pascals-triangle_exercism-javascript-ffflorian_ffflorian",
          "javascript_pascals-triangle_exercism-javascript-PhymasSC",
          "javascript_pascals-triangle_exercism-javascript-PhymasSC_PhymasSC"
        ]
      }
    },
    "perfect_numbers": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 27,
        "by_llm": {
          "openAI": 8,
          "claude": 9,
          "gemini": 10
        },
        "by_prompt_version": {
          "v1": 3,
          "v2": 7,
          "v3": 9,
          "v4": 8
        },
        "by_metric": {
          "execution_time_ms": 18,
          "RAM_usage": 9
        },
        "affected_entries": [
          "typescript_perfect-numbers_Exercism-typescript-shybyte_shybyte",
          "javascript_perfect-numbers_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "perfect-numbers_27"
        ]
      }
    },
    "perfect_rectangle": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "perfect_rectangle_225"
        ]
      }
    },
    "permutation_in_string": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "permutation_in_string_144"
        ]
      }
    },
    "phone_number": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 84,
        "by_llm": {
          "openAI": 28,
          "claude": 28,
          "gemini": 28
        },
        "by_prompt_version": {
          "v1": 21,
          "v2": 21,
          "v3": 21,
          "v4": 21
        },
        "by_metric": {
          "execution_time_ms": 72,
          "RAM_usage": 12
        },
        "affected_entries": [
          "javascript_phone-number_exercism-javascript-bearguns",
          "phone-number_28",
          "javascript_phone-number_exercism-javascript-ThomasZumsteg",
          "javascript_phone-number_exercism-javascript-bearguns_bearguns",
          "Java_phone-number_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_phone-number_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "pig_latin": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 57,
        "by_llm": {
          "openAI": 17,
          "claude": 20,
          "gemini": 20
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 15,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 57
        },
        "affected_entries": [
          "Java_pig-latin_exercism-java-ThomasZumsteg",
          "javascript_pig-latin_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "Java_pig-latin_exercism-java-blogscot_blogscot",
          "javascript_pig-latin_exercism-javascript-ffflorian_ffflorian",
          "Java_pig-latin_exercism-java-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "postfix_evaluate": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "postfix_evaluate_256"
        ]
      }
    },
    "power": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "power_257"
        ]
      }
    },
    "power_set": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "power_set_258"
        ]
      }
    },
    "prime_factors": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 63,
        "by_llm": {
          "openAI": 21,
          "claude": 21,
          "gemini": 21
        },
        "by_prompt_version": {
          "v2": 21,
          "v3": 21,
          "v4": 21
        },
        "by_metric": {
          "execution_time_ms": 45,
          "RAM_usage": 18
        },
        "affected_entries": [
          "cpp_prime_factors_Exercism (cmccandless)",
          "javascript_prime-factors_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_prime-factors_exercism-javascript-ThomasZumsteg",
          "prime_factors_241",
          "Java_prime-factors_exercism-java-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "product_of_array_except_self": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 36,
        "by_llm": {
          "openAI": 12,
          "claude": 12,
          "gemini": 12
        },
        "by_prompt_version": {
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 18,
          "RAM_usage": 18
        },
        "affected_entries": [
          "product_of_array_except_self_187",
          "product_of_array_except_self_145"
        ]
      }
    },
    "protein_translation": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 84,
        "by_llm": {
          "openAI": 28,
          "claude": 28,
          "gemini": 28
        },
        "by_prompt_version": {
          "v1": 21,
          "v2": 21,
          "v3": 21,
          "v4": 21
        },
        "by_metric": {
          "execution_time_ms": 48,
          "RAM_usage": 24,
          "CPU_usage": 12
        },
        "affected_entries": [
          "go_protein_translation_Exercism (go_rootulp)",
          "Java_protein-translation_exercism-java-blogscot",
          "protein-translation_29",
          "Java_protein-translation_exercism-java-blogscot_blogscot"
        ]
      }
    },
    "protein_translator": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "java_protein_translation_aaron-contreras"
        ]
      }
    },
    "proverb": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 36,
        "by_llm": {
          "openAI": 12,
          "claude": 12,
          "gemini": 12
        },
        "by_prompt_version": {
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 36
        },
        "affected_entries": [
          "javascript_proverb_exercism-javascript-ffflorian_ffflorian",
          "javascript_proverb_exercism-javascript-ffflorian",
          "Java_proverb_exercism-java-blogscot_blogscot",
          "javascript_proverb_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "pythagorean_triplet": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 36,
        "by_llm": {
          "openAI": 12,
          "claude": 12,
          "gemini": 12
        },
        "by_prompt_version": {
          "v1": 9,
          "v2": 9,
          "v3": 9,
          "v4": 9
        },
        "by_metric": {
          "execution_time_ms": 36
        },
        "affected_entries": [
          "java_pythagorean-triplet_stuartnankai",
          "javascript_pythagorean-triplet_exercism-javascript-ThomasZumsteg",
          "javascript_pythagorean-triplet_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "queen": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "java_queen-attack_stuartnankai",
          "java_queen_attack_stuartnankai"
        ]
      }
    },
    "queen_attack": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "CPU_usage": 9
        },
        "affected_entries": [
          "javascript_queen-attack_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "typescript_queen-attack_Exercism-typescript-shybyte_shybyte"
        ]
      }
    },
    "queens_problem": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "queens_problem_259"
        ]
      }
    },
    "raindrops": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 2,
        "by_llm": {
          "claude": 1,
          "gemini": 1
        },
        "by_prompt_version": {
          "v3": 1,
          "v4": 1
        },
        "by_metric": {
          "execution_time_ms": 2
        },
        "affected_entries": [
          "c_raindrops_Exercism (chriswilding)",
          "c_raindrops_Exercism (vlzware)"
        ]
      }
    },
    "random_sample": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "random_sample_188"
        ]
      }
    },
    "ransom_note": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "ransom_note_172"
        ]
      }
    },
    "rational_numbers": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 1,
        "by_llm": {
          "gemini": 1
        },
        "by_prompt_version": {
          "v1": 1
        },
        "by_metric": {
          "execution_time_ms": 1
        },
        "affected_entries": [
          "typescript_rational-numbers_Exercism-typescript-FilipeCerejo"
        ]
      }
    },
    "rectangles": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 18
        },
        "affected_entries": [
          "javascript_rectangles_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_rectangles_exercism-javascript-ThomasZumsteg"
        ]
      }
    },
    "resistor_color": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 48,
        "by_llm": {
          "openAI": 16,
          "claude": 16,
          "gemini": 16
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 48
        },
        "affected_entries": [
          "javascript_resistor-color_exercism-javascript-programmiri_programmiri",
          "java_resistor_color_Anarghya-Rao",
          "Java_resistor-color_exercism-java-uzilan_robiworks",
          "javascript_resistor-color_exercism-javascript-programmiri"
        ]
      }
    },
    "resistor_color_duo": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 72,
        "by_llm": {
          "openAI": 24,
          "claude": 24,
          "gemini": 24
        },
        "by_prompt_version": {
          "v1": 18,
          "v2": 18,
          "v3": 18,
          "v4": 18
        },
        "by_metric": {
          "execution_time_ms": 72
        },
        "affected_entries": [
          "Java_resistor-color-duo_exercism-java-uzilan_robiworks",
          "javascript_resistor-color-duo_exercism-javascript-ffflorian_ffflorian",
          "javascript_resistor-color-duo_exercism-javascript-PhymasSC_PhymasSC",
          "javascript_resistor-color-duo_exercism-javascript-oguzsh_oguzsh",
          "javascript_resistor-color-duo_exercism-javascript-programmiri_programmiri",
          "javascript_resistor-color-duo_exercism-javascript-ffflorian"
        ]
      }
    },
    "reverse_all_lists": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "reverse_all_lists_260"
        ]
      }
    },
    "reverse_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "reverse_array_189"
        ]
      }
    },
    "reverse_ascending_sublists": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "reverse_ascending_sublists_190"
        ]
      }
    },
    "reverse_integer": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "reverse_integer_261"
        ]
      }
    },
    "reverse_string": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 81,
        "by_llm": {
          "openAI": 27,
          "claude": 27,
          "gemini": 27
        },
        "by_prompt_version": {
          "v2": 27,
          "v3": 27,
          "v4": 27
        },
        "by_metric": {
          "execution_time_ms": 81
        },
        "affected_entries": [
          "Java_reverse-string_exercism-java-blogscot_blogscot",
          "javascript_reverse-string_exercism-javascript-oguzsh",
          "Java_reverse-string_exercism-java-uzilan_robiworks",
          "javascript_reverse-string_exercism-javascript-bearguns_bearguns",
          "java_reverse_string_aaron-contreras",
          "javascript_reverse-string_exercism-javascript-oguzsh_oguzsh",
          "javascript_reverse-string_exercism-javascript-programmiri_programmiri",
          "javascript_reverse-string_exercism-javascript-irvingbennett_irvingbennett",
          "javascript_reverse-string_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "reverse_vowels": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "reverse_vowels_272"
        ]
      }
    },
    "reverse_words_in_sentence": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "reverse_words_in_sentence_273"
        ]
      }
    },
    "river_sizes": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "river_sizes_262"
        ]
      }
    },
    "rna_transcription": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 135,
        "by_llm": {
          "openAI": 45,
          "claude": 45,
          "gemini": 45
        },
        "by_prompt_version": {
          "v2": 45,
          "v3": 45,
          "v4": 45
        },
        "by_metric": {
          "execution_time_ms": 135
        },
        "affected_entries": [
          "javascript_rna-transcription_exercism-javascript-PhymasSC",
          "javascript_rna-transcription_exercism-javascript-irvingbennett_irvingbennett",
          "javascript_rna-transcription_exercism-javascript-irvingbennett",
          "javascript_rna-transcription_exercism-javascript-oguzsh_oguzsh",
          "javascript_rna-transcription_exercism-javascript-ThomasZumsteg",
          "javascript_rna-transcription_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "java_rna_transcription_Anarghya-Rao",
          "Java_rna-transcription_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_rna-transcription_exercism-javascript-programmiri_programmiri",
          "javascript_rna-transcription_exercism-javascript-programmiri",
          "Java_rna-transcription_exercism-java-blogscot",
          "Java_rna-transcription_exercism-java-uzilan_robiworks",
          "javascript_rna-transcription_exercism-javascript-PhymasSC_PhymasSC",
          "javascript_rna-transcription_exercism-javascript-ffflorian_ffflorian",
          "Java_rna-transcription_exercism-java-blogscot_blogscot"
        ]
      }
    },
    "robot_name": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 72,
        "by_llm": {
          "openAI": 24,
          "claude": 24,
          "gemini": 24
        },
        "by_prompt_version": {
          "v1": 18,
          "v2": 18,
          "v3": 18,
          "v4": 18
        },
        "by_metric": {
          "execution_time_ms": 60,
          "RAM_usage": 12
        },
        "affected_entries": [
          "Java_robot-name_exercism-java-ThomasZumsteg",
          "robot-name_31",
          "Java_robot-name_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_robot-name_exercism-javascript-ffflorian",
          "javascript_robot-name_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "robot_simulator": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "javascript_robot-simulator_exercism-javascript-ThomasZumsteg",
          "javascript_robot-simulator_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "roman_numerals": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 36,
        "by_llm": {
          "openAI": 12,
          "claude": 12,
          "gemini": 12
        },
        "by_prompt_version": {
          "v1": 9,
          "v2": 9,
          "v3": 9,
          "v4": 9
        },
        "by_metric": {
          "execution_time_ms": 36
        },
        "affected_entries": [
          "javascript_roman-numerals_exercism-javascript-programmiri_programmiri",
          "Java_roman-numerals_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_roman-numerals_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "rotate_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "rotate_array_191"
        ]
      }
    },
    "rotational_cipher": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 45,
        "by_llm": {
          "openAI": 15,
          "claude": 15,
          "gemini": 15
        },
        "by_prompt_version": {
          "v2": 15,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 36,
          "RAM_usage": 9
        },
        "affected_entries": [
          "javascript_rotational-cipher_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "rotational-cipher_32",
          "javascript_rotational-cipher_exercism-javascript-ThomasZumsteg",
          "javascript_rotational-cipher_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "run_length_encoding": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 38,
        "by_llm": {
          "gemini": 13,
          "claude": 13,
          "openAI": 12
        },
        "by_prompt_version": {
          "v1": 2,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 38
        },
        "affected_entries": [
          "typescript_run-length-encoding_Exercism-typescript-shybyte",
          "javascript_run-length-encoding_exercism-javascript-programmiri_programmiri",
          "javascript_run-length-encoding_exercism-javascript-ffflorian",
          "javascript_run-length-encoding_exercism-javascript-programmiri",
          "javascript_run-length-encoding_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "saddle_points": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "javascript_saddle-points_exercism-javascript-ThomasZumsteg",
          "javascript_saddle-points_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "scale_generator": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "javascript_scale-generator_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "scrabble_score": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 90,
        "by_llm": {
          "openAI": 30,
          "claude": 30,
          "gemini": 30
        },
        "by_prompt_version": {
          "v2": 30,
          "v3": 30,
          "v4": 30
        },
        "by_metric": {
          "execution_time_ms": 63,
          "RAM_usage": 9,
          "CPU_usage": 18
        },
        "affected_entries": [
          "javascript_scrabble-score_exercism-javascript-ffflorian_ffflorian",
          "Java_scrabble-score_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "typescript_scrabble-score_Exercism-typescript-thewanionly_thewanionly",
          "Java_scrabble-score_exercism-java-ThomasZumsteg",
          "Java_scrabble-score_exercism-java-uzilan_robiworks",
          "javascript_scrabble-score_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "typescript_scrabble-score_Exercism-typescript-thewanionly",
          "scrabble-score_33",
          "javascript_scrabble-score_exercism-javascript-ffflorian"
        ]
      }
    },
    "search_2d_matrix": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "search_2d_matrix_264"
        ]
      }
    },
    "secret_handshake": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 12,
        "by_llm": {
          "openAI": 4,
          "claude": 4,
          "gemini": 4
        },
        "by_prompt_version": {
          "v1": 3,
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 12
        },
        "affected_entries": [
          "javascript_secret-handshake_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "series": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "series_34"
        ]
      }
    },
    "set_matrix_zeroes": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "set_matrix_zeroes_265"
        ]
      }
    },
    "shuffle_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "shuffle_array_194"
        ]
      }
    },
    "sieve": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 24
        },
        "affected_entries": [
          "javascript_sieve_exercism-javascript-ffflorian",
          "javascript_sieve_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "simple_cipher": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 54,
        "by_llm": {
          "openAI": 18,
          "claude": 18,
          "gemini": 18
        },
        "by_prompt_version": {
          "v2": 18,
          "v3": 18,
          "v4": 18
        },
        "by_metric": {
          "execution_time_ms": 36,
          "CPU_usage": 18
        },
        "affected_entries": [
          "javascript_simple-cipher_exercism-javascript-ThomasZumsteg",
          "javascript_simple-cipher_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "Java_simple-cipher_exercism-java-ThomasZumsteg",
          "typescript_simple-cipher_Exercism-typescript-FilipeCerejo_FilipeCerejo",
          "typescript_simple-cipher_Exercism-typescript-FilipeCerejo",
          "Java_simple-cipher_exercism-java-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "simple_linked_list": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "javascript_simple-linked-list_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "sliding_window_maximum": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "sliding_window_maximum_173"
        ]
      }
    },
    "smallest_multiple": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "smallest_multiple_242"
        ]
      }
    },
    "snakes_and_ladders": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "snakes_and_ladders_146"
        ]
      }
    },
    "sort_rgb_array": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "sort_rgb_array_195"
        ]
      }
    },
    "space_age": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 120,
        "by_llm": {
          "openAI": 40,
          "claude": 40,
          "gemini": 40
        },
        "by_prompt_version": {
          "v1": 30,
          "v2": 30,
          "v3": 30,
          "v4": 30
        },
        "by_metric": {
          "execution_time_ms": 120
        },
        "affected_entries": [
          "javascript_space-age_exercism-javascript-irvingbennett_irvingbennett",
          "javascript_space-age_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_space-age_exercism-javascript-PhymasSC_PhymasSC",
          "Java_space-age_exercism-java-blogscot_blogscot",
          "Java_space-age_exercism-java-uzilan_robiworks",
          "javascript_space-age_exercism-javascript-programmiri_programmiri",
          "javascript_space-age_exercism-javascript-oguzsh_oguzsh",
          "Java_space-age_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_space-age_exercism-javascript-oguzsh",
          "Java_space-age_exercism-java-ThomasZumsteg"
        ]
      }
    },
    "spiral_matrix": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 60,
        "by_llm": {
          "openAI": 20,
          "claude": 20,
          "gemini": 20
        },
        "by_prompt_version": {
          "v1": 15,
          "v2": 15,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 48,
          "RAM_usage": 12
        },
        "affected_entries": [
          "javascript_spiral-matrix_exercism-javascript-irvingbennett",
          "Java_spiral-matrix_exercism-java-shyvum_shyvum",
          "javascript_spiral-matrix_exercism-javascript-irvingbennett_irvingbennett",
          "spiral_matrix_266"
        ]
      }
    },
    "split_coins": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "split_coins_214"
        ]
      }
    },
    "square_root": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "square-root_35"
        ]
      }
    },
    "strain": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 18
        },
        "affected_entries": [
          "javascript_strain_exercism-javascript-ffflorian_ffflorian",
          "javascript_strain_exercism-javascript-ffflorian"
        ]
      }
    },
    "sublist": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 36,
        "by_llm": {
          "openAI": 12,
          "claude": 12,
          "gemini": 12
        },
        "by_prompt_version": {
          "v1": 9,
          "v2": 9,
          "v3": 9,
          "v4": 9
        },
        "by_metric": {
          "execution_time_ms": 36
        },
        "affected_entries": [
          "javascript_sublist_exercism-javascript-bearguns_bearguns",
          "javascript_sublist_exercism-javascript-ThomasZumsteg",
          "javascript_sublist_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "sum_non_adjecent": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "sum_non-adjecent_215"
        ]
      }
    },
    "sum_of_multiples": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 48,
        "by_llm": {
          "openAI": 16,
          "claude": 16,
          "gemini": 16
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 48
        },
        "affected_entries": [
          "java_sum-of-multiples_stuartnankai",
          "java_sum_of_multiples_stuartnankai",
          "javascript_sum-of-multiples_exercism-javascript-ffflorian_ffflorian",
          "javascript_sum-of-multiples_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "summary_ranges": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "summary_ranges_174"
        ]
      }
    },
    "swap_first_and_last_word": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "swap_first_and_last_word_275"
        ]
      }
    },
    "three_sum": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "three_sum_147"
        ]
      }
    },
    "transpose": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 48,
        "by_llm": {
          "openAI": 16,
          "claude": 16,
          "gemini": 16
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 48
        },
        "affected_entries": [
          "javascript_transpose_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "javascript_transpose_exercism-javascript-ThomasZumsteg",
          "javascript_transpose_exercism-javascript-ffflorian",
          "javascript_transpose_exercism-javascript-ffflorian_ffflorian"
        ]
      }
    },
    "triangle": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 72,
        "by_llm": {
          "openAI": 24,
          "claude": 24,
          "gemini": 24
        },
        "by_prompt_version": {
          "v1": 18,
          "v2": 18,
          "v3": 18,
          "v4": 18
        },
        "by_metric": {
          "execution_time_ms": 60,
          "RAM_usage": 12
        },
        "affected_entries": [
          "triangle_36",
          "javascript_triangle_exercism-javascript-irvingbennett_irvingbennett",
          "javascript_triangle_exercism-javascript-ffflorian_ffflorian",
          "javascript_triangle_exercism-javascript-oguzsh_oguzsh",
          "javascript_triangle_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "twelve_days": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 60,
        "by_llm": {
          "openAI": 20,
          "claude": 20,
          "gemini": 20
        },
        "by_prompt_version": {
          "v1": 15,
          "v2": 15,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 48,
          "RAM_usage": 12
        },
        "affected_entries": [
          "Java_twelve-days_exercism-java-blogscot",
          "twelve-days_37",
          "Java_twelve-days_exercism-java-blogscot_blogscot",
          "javascript_twelve-days_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    },
    "two_bucket": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 45,
        "by_llm": {
          "openAI": 15,
          "claude": 15,
          "gemini": 15
        },
        "by_prompt_version": {
          "v2": 15,
          "v3": 15,
          "v4": 15
        },
        "by_metric": {
          "execution_time_ms": 18,
          "CPU_usage": 27
        },
        "affected_entries": [
          "javascript_two-bucket_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "typescript_two-bucket_Exercism-typescript-shybyte_shybyte",
          "typescript_two-bucket_Exercism-typescript-thewanionly",
          "typescript_two-bucket_Exercism-typescript-thewanionly_thewanionly",
          "javascript_two-bucket_exercism-javascript-ThomasZumsteg"
        ]
      }
    },
    "two_fer": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 81,
        "by_llm": {
          "openAI": 27,
          "claude": 27,
          "gemini": 27
        },
        "by_prompt_version": {
          "v2": 27,
          "v3": 27,
          "v4": 27
        },
        "by_metric": {
          "execution_time_ms": 72,
          "RAM_usage": 9
        },
        "affected_entries": [
          "Java_two-fer_exercism-java-blogscot_blogscot",
          "javascript_two-fer_exercism-javascript-oguzsh",
          "javascript_two-fer_exercism-javascript-oguzsh_oguzsh",
          "javascript_two-fer_exercism-javascript-programmiri",
          "javascript_two-fer_exercism-javascript-programmiri_programmiri",
          "javascript_two-fer_exercism-javascript-ThomasZumsteg_ThomasZumsteg",
          "Java_two-fer_exercism-java-uzilan_robiworks",
          "two-fer_38"
        ]
      }
    },
    "two_sum_ii_input_array_is_sorted": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 18,
        "by_llm": {
          "openAI": 6,
          "claude": 6,
          "gemini": 6
        },
        "by_prompt_version": {
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 9,
          "RAM_usage": 9
        },
        "affected_entries": [
          "two_sum_ii_input_array_is_sorted_149"
        ]
      }
    },
    "twofer": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 9,
        "by_llm": {
          "openAI": 3,
          "claude": 3,
          "gemini": 3
        },
        "by_prompt_version": {
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 9
        },
        "affected_entries": [
          "java_two_fer_Schenz"
        ]
      }
    },
    "unique_paths": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "unique_paths_244"
        ]
      }
    },
    "valid_palindrome": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "valid_palindrome_177"
        ]
      }
    },
    "valid_parentheses": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 48,
        "by_llm": {
          "openAI": 16,
          "claude": 16,
          "gemini": 16
        },
        "by_prompt_version": {
          "v1": 12,
          "v2": 12,
          "v3": 12,
          "v4": 12
        },
        "by_metric": {
          "execution_time_ms": 24,
          "RAM_usage": 24
        },
        "affected_entries": [
          "valid_parentheses_178",
          "valid_parentheses_267"
        ]
      }
    },
    "valid_sudoku": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "valid_sudoku_150"
        ]
      }
    },
    "word_break": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 24,
        "by_llm": {
          "openAI": 8,
          "claude": 8,
          "gemini": 8
        },
        "by_prompt_version": {
          "v1": 6,
          "v2": 6,
          "v3": 6,
          "v4": 6
        },
        "by_metric": {
          "execution_time_ms": 12,
          "RAM_usage": 12
        },
        "affected_entries": [
          "word_break_217"
        ]
      }
    },
    "word_count": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 93,
        "by_llm": {
          "openAI": 30,
          "claude": 31,
          "gemini": 32
        },
        "by_prompt_version": {
          "v2": 32,
          "v3": 30,
          "v4": 31
        },
        "by_metric": {
          "execution_time_ms": 66,
          "RAM_usage": 27
        },
        "affected_entries": [
          "c_word_count_Exercism (ThomasZumsteg)",
          "Java_word-count_exercism-java-ThomasZumsteg_ThomasZumsteg",
          "javascript_word-count_exercism-javascript-programmiri_programmiri",
          "javascript_word-count_exercism-javascript-ffflorian",
          "c_word_count_Exercism (paddydoyle)",
          "Java_word-count_exercism-java-ThomasZumsteg",
          "javascript_word-count_exercism-javascript-ffflorian_ffflorian",
          "word-count_39"
        ]
      }
    },
    "word_search": {
      "base_success": true,
      "llm_success": true,
      "overall_success": true,
      "outlier_details": {
        "total_outliers": 12,
        "by_llm": {
          "openAI": 4,
          "claude": 4,
          "gemini": 4
        },
        "by_prompt_version": {
          "v1": 3,
          "v2": 3,
          "v3": 3,
          "v4": 3
        },
        "by_metric": {
          "execution_time_ms": 12
        },
        "affected_entries": [
          "javascript_word-search_exercism-javascript-ThomasZumsteg_ThomasZumsteg"
        ]
      }
    }
  },
  "summary": {
    "total_clusters": 182,
    "fully_successful": 182,
    "partially_successful": 0,
    "success_rate": 100.0
  }
}
{
  "chaitanas-colossal-coaster_6": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 79.6,
      "avg_exec_RAM_usage": 13900.8,
      "avg_exec_execution_time_ms": 24.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 72.8,
          "avg_exec_RAM_usage": 13875.2,
          "avg_exec_execution_time_ms": 26.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 79.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 84.0,
          "avg_exec_RAM_usage": 13926.4,
          "avg_exec_execution_time_ms": 26.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 8.542713567839193,
          "RAM_usage": 0.18416206261509083,
          "execution_time_ms": -8.333333333333332,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 0.7537688442210985,
          "RAM_usage": -0.36832412523020785,
          "execution_time_ms": -33.33333333333333,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -5.527638190954781,
          "RAM_usage": -0.18416206261510393,
          "execution_time_ms": -8.333333333333332,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 37.1859296482412,
          "RAM_usage": -475.50644567219155,
          "execution_time_ms": -4066.6666666666665,
          "regressionTestPassed": -0.0
        }
      }
    }
  }
}
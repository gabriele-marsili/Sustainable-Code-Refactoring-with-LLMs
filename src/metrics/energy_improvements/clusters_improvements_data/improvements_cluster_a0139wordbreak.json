{
  "a0139wordbreak_84": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 77.8,
      "avg_exec_RAM_usage": 14182.4,
      "avg_exec_execution_time_ms": 26.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 79.8,
          "avg_exec_RAM_usage": 14182.4,
          "avg_exec_execution_time_ms": 45.8,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 87.2,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 36.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 84.8,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 40.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -2.570694087403599,
          "RAM_usage": 0.0,
          "execution_time_ms": -76.15384615384613,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -12.082262210796923,
          "RAM_usage": -0.18050541516245744,
          "execution_time_ms": -38.46153846153847,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -8.997429305912597,
          "RAM_usage": -0.18050541516245744,
          "execution_time_ms": -53.84615384615385,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.732647814910024,
          "RAM_usage": -464.0794223826715,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        }
      }
    }
  }
}
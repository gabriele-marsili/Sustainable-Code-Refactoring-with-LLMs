{
  "a0000blank_40": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 78.2,
      "avg_exec_RAM_usage": 13900.8,
      "avg_exec_execution_time_ms": 34.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 66.2,
          "avg_exec_RAM_usage": 13875.2,
          "avg_exec_execution_time_ms": 30.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 83.4,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 34.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 78.6,
          "avg_exec_RAM_usage": 13849.6,
          "avg_exec_execution_time_ms": 36.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 77.8,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 40.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 67.0,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 40.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 80.4,
          "avg_exec_RAM_usage": 13926.4,
          "avg_exec_execution_time_ms": 38.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 83.4,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 34.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 83.8,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 68.2,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 78.0,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 46.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 81.6,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 79.8,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 44.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 15.34526854219949,
          "RAM_usage": 0.18416206261509083,
          "execution_time_ms": 11.76470588235294,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -6.649616368286448,
          "RAM_usage": -0.36832412523020785,
          "execution_time_ms": 0.0,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -0.5115089514066388,
          "RAM_usage": 0.36832412523019475,
          "execution_time_ms": -5.88235294117647,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 0.5115089514066569,
          "RAM_usage": 0.0,
          "execution_time_ms": -17.647058823529413,
          "regressionTestPassed": -0.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 14.32225063938619,
          "RAM_usage": 0.0,
          "execution_time_ms": -17.647058823529413,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -2.8132992327365764,
          "RAM_usage": -0.18416206261510393,
          "execution_time_ms": -11.76470588235294,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -6.649616368286448,
          "RAM_usage": 0.0,
          "execution_time_ms": 0.0,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -7.161125319693087,
          "RAM_usage": -0.36832412523020785,
          "execution_time_ms": 5.88235294117647,
          "regressionTestPassed": -0.0
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 12.787723785166241,
          "RAM_usage": 0.0,
          "execution_time_ms": 5.88235294117647,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 0.25575447570332843,
          "RAM_usage": 0.0,
          "execution_time_ms": -35.294117647058826,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -4.347826086956511,
          "RAM_usage": -0.36832412523020785,
          "execution_time_ms": 5.88235294117647,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -2.046035805626591,
          "RAM_usage": 0.0,
          "execution_time_ms": -29.411764705882355,
          "regressionTestPassed": -0.0
        }
      }
    }
  }
}
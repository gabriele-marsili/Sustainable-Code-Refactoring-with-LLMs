{
  "count_triplets_with_sum_k_179": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 10.4,
      "avg_exec_RAM_usage": 13849.6,
      "avg_exec_execution_time_ms": 32.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 4,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 11.0,
          "avg_exec_RAM_usage": 13824.0,
          "avg_exec_execution_time_ms": 70.0,
          "avg_exec_regressionTestPassed": 20.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 3,
          "language": "python",
          "avg_exec_CPU_usage": 11.666666666666666,
          "avg_exec_RAM_usage": 13781.333333333334,
          "avg_exec_execution_time_ms": 43.333333333333336,
          "avg_exec_regressionTestPassed": 60.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 6.0,
          "avg_exec_RAM_usage": 12032.0,
          "avg_exec_execution_time_ms": 250.0,
          "avg_exec_regressionTestPassed": 20.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 3,
          "language": "python",
          "avg_exec_CPU_usage": 12.333333333333334,
          "avg_exec_RAM_usage": 13824.0,
          "avg_exec_execution_time_ms": 46.666666666666664,
          "avg_exec_regressionTestPassed": 60.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 3,
          "language": "python",
          "avg_exec_CPU_usage": 7.333333333333333,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 53.333333333333336,
          "avg_exec_regressionTestPassed": 60.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 16.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 50.0,
          "avg_exec_regressionTestPassed": 20.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 4,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 6.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 69.0,
          "avg_exec_regressionTestPassed": 25.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 3,
          "language": "python",
          "avg_exec_CPU_usage": 12.333333333333334,
          "avg_exec_RAM_usage": 13781.333333333334,
          "avg_exec_execution_time_ms": 53.333333333333336,
          "avg_exec_regressionTestPassed": 60.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 9.0,
          "avg_exec_RAM_usage": 13824.0,
          "avg_exec_execution_time_ms": 50.0,
          "avg_exec_regressionTestPassed": 20.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 6.0,
          "avg_exec_RAM_usage": 12032.0,
          "avg_exec_execution_time_ms": 250.0,
          "avg_exec_regressionTestPassed": 20.0
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 4,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -5.769230769230766,
          "RAM_usage": 0.18484288354898598,
          "execution_time_ms": -118.75,
          "regressionTestPassed": -80.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 3,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -12.17948717948717,
          "RAM_usage": 0.4929143561306205,
          "execution_time_ms": -35.41666666666667,
          "regressionTestPassed": -40.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.30769230769231,
          "RAM_usage": 13.12384473197782,
          "execution_time_ms": -681.25,
          "regressionTestPassed": -80.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 3,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -18.58974358974359,
          "RAM_usage": 0.18484288354898598,
          "execution_time_ms": -45.83333333333333,
          "regressionTestPassed": -40.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 3,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 29.487179487179493,
          "RAM_usage": -0.7393715341959308,
          "execution_time_ms": -66.66666666666667,
          "regressionTestPassed": -40.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -53.84615384615385,
          "RAM_usage": -0.7393715341959308,
          "execution_time_ms": -56.25,
          "regressionTestPassed": -80.0
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 4,
          "language": "python",
          "CPU_usage": 42.30769230769231,
          "RAM_usage": -0.7393715341959308,
          "execution_time_ms": -115.625,
          "regressionTestPassed": -75.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 3,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -18.58974358974359,
          "RAM_usage": 0.4929143561306205,
          "execution_time_ms": -66.66666666666667,
          "regressionTestPassed": -40.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 13.461538461538463,
          "RAM_usage": 0.18484288354898598,
          "execution_time_ms": -56.25,
          "regressionTestPassed": -80.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.30769230769231,
          "RAM_usage": 13.12384473197782,
          "execution_time_ms": -681.25,
          "regressionTestPassed": -80.0
        }
      }
    }
  }
}
{
  "check_if_point_inside_polygon_236": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 87.4,
      "avg_exec_RAM_usage": 13926.4,
      "avg_exec_execution_time_ms": 20.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 22.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 40.0,
          "avg_exec_regressionTestPassed": 20.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 37.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 30.0,
          "avg_exec_regressionTestPassed": 20.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v2": {
          "exec_quantity": 6,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v3": {
          "exec_quantity": 8,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 15.0,
          "avg_exec_RAM_usage": 13824.0,
          "avg_exec_execution_time_ms": 30.0,
          "avg_exec_regressionTestPassed": 12.5
        },
        "prompt_v4": {
          "exec_quantity": 6,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v2": {
          "exec_quantity": 6,
          "successfully_exec_quantity": 0,
          "language": "python",
          "avg_exec_CPU_usage": -1,
          "avg_exec_RAM_usage": -1,
          "avg_exec_execution_time_ms": -1,
          "avg_exec_regressionTestPassed": 0.0
        },
        "prompt_v3": {
          "exec_quantity": 7,
          "successfully_exec_quantity": 2,
          "language": "python",
          "avg_exec_CPU_usage": 10.0,
          "avg_exec_RAM_usage": 13760.0,
          "avg_exec_execution_time_ms": 35.0,
          "avg_exec_regressionTestPassed": 28.57142857142857
        },
        "prompt_v4": {
          "exec_quantity": 6,
          "successfully_exec_quantity": 1,
          "language": "python",
          "avg_exec_CPU_usage": 9.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 30.0,
          "avg_exec_regressionTestPassed": 16.666666666666664
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 74.8283752860412,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -100.0,
          "regressionTestPassed": -80.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 57.66590389016019,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -50.0,
          "regressionTestPassed": -80.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 6,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 8,
          "language": "python",
          "CPU_usage": 82.83752860411899,
          "RAM_usage": 0.7352941176470562,
          "execution_time_ms": -50.0,
          "regressionTestPassed": -87.5
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 6,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 0,
          "LLM_exec_quantity": 6,
          "language": "python",
          "CPU_usage": -999,
          "RAM_usage": -999,
          "execution_time_ms": -999,
          "regressionTestPassed": -999
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 2,
          "LLM_exec_quantity": 7,
          "language": "python",
          "CPU_usage": 88.558352402746,
          "RAM_usage": 1.1948529411764681,
          "execution_time_ms": -75.0,
          "regressionTestPassed": -71.42857142857143
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 1,
          "LLM_exec_quantity": 6,
          "language": "python",
          "CPU_usage": 89.7025171624714,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -50.0,
          "regressionTestPassed": -83.33333333333334
        }
      }
    }
  }
}
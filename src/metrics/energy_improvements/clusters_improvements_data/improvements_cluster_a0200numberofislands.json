{
  "a0200numberofislands_101": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 78.4,
      "avg_exec_RAM_usage": 14208.0,
      "avg_exec_execution_time_ms": 26.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 82.6,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 22.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 37.8,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 34.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 3,
          "language": "python",
          "avg_exec_CPU_usage": 54.333333333333336,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 33.333333333333336,
          "avg_exec_regressionTestPassed": 60.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 44.0,
          "avg_exec_RAM_usage": 14156.8,
          "avg_exec_execution_time_ms": 46.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 80.0,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 4,
          "language": "python",
          "avg_exec_CPU_usage": 41.5,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 30.0,
          "avg_exec_regressionTestPassed": 80.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 28.2,
          "avg_exec_RAM_usage": 14182.4,
          "avg_exec_execution_time_ms": 64.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.2,
          "avg_exec_RAM_usage": 14182.4,
          "avg_exec_execution_time_ms": 42.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 83.4,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 22.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 47.8,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 48.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 4,
          "language": "python",
          "avg_exec_CPU_usage": 37.0,
          "avg_exec_RAM_usage": 14144.0,
          "avg_exec_execution_time_ms": 100.0,
          "avg_exec_regressionTestPassed": 80.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 45.8,
          "avg_exec_RAM_usage": 14208.0,
          "avg_exec_execution_time_ms": 40.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -5.3571428571428426,
          "RAM_usage": 0.0,
          "execution_time_ms": 15.384615384615385,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 51.78571428571429,
          "RAM_usage": 0.0,
          "execution_time_ms": -30.76923076923077,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 3,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 30.69727891156463,
          "RAM_usage": 0.0,
          "execution_time_ms": -28.205128205128215,
          "regressionTestPassed": -40.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 43.87755102040817,
          "RAM_usage": 0.3603603603603655,
          "execution_time_ms": -76.92307692307693,
          "regressionTestPassed": -0.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -2.0408163265306047,
          "RAM_usage": 0.0,
          "execution_time_ms": -23.076923076923077,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 4,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 47.06632653061225,
          "RAM_usage": 0.0,
          "execution_time_ms": -15.384615384615385,
          "regressionTestPassed": -20.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 64.03061224489795,
          "RAM_usage": 0.18018018018018275,
          "execution_time_ms": -146.15384615384613,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 35.96938775510204,
          "RAM_usage": 0.18018018018018275,
          "execution_time_ms": -61.53846153846154,
          "regressionTestPassed": -0.0
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -6.377551020408164,
          "RAM_usage": 0.0,
          "execution_time_ms": 15.384615384615385,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 39.030612244897966,
          "RAM_usage": 0.0,
          "execution_time_ms": -84.61538461538461,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 4,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 52.8061224489796,
          "RAM_usage": 0.45045045045045046,
          "execution_time_ms": -284.61538461538464,
          "regressionTestPassed": -20.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 41.581632653061234,
          "RAM_usage": 0.0,
          "execution_time_ms": -53.84615384615385,
          "regressionTestPassed": -0.0
        }
      }
    }
  }
}
{
  "valid_anagram_176": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 86.6,
      "avg_exec_RAM_usage": 13824.0,
      "avg_exec_execution_time_ms": 26.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 78.6,
          "avg_exec_RAM_usage": 13926.4,
          "avg_exec_execution_time_ms": 53.8,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 81.4,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 48.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 82.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 36.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 50.0,
          "avg_exec_RAM_usage": 80000.0,
          "avg_exec_execution_time_ms": 1000.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 9.237875288683602,
          "RAM_usage": -0.740740740740738,
          "execution_time_ms": -106.92307692307692,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 6.004618937644329,
          "RAM_usage": -0.5555555555555503,
          "execution_time_ms": -84.61538461538461,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 5.3117782909930655,
          "RAM_usage": -0.9259259259259258,
          "execution_time_ms": -38.46153846153847,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 42.263279445727484,
          "RAM_usage": -478.7037037037037,
          "execution_time_ms": -3746.153846153846,
          "regressionTestPassed": -0.0
        }
      }
    }
  }
}
{
  "a0146lrucache_88": {
    "base_5_exec_data": {
      "exec_quantity": 5,
      "language": "python",
      "avg_exec_CPU_usage": 81.4,
      "avg_exec_RAM_usage": 13926.4,
      "avg_exec_execution_time_ms": 26.0
    },
    "LLM_5_exec_data": {
      "openAI": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 81.8,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 78.6,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 36.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 75.6,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 40.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 79.0,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 80.4,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 30.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 82.8,
          "avg_exec_RAM_usage": 13875.2,
          "avg_exec_execution_time_ms": 24.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 84.4,
          "avg_exec_RAM_usage": 13926.4,
          "avg_exec_execution_time_ms": 24.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 82.6,
          "avg_exec_RAM_usage": 13977.6,
          "avg_exec_execution_time_ms": 26.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      },
      "claude": {
        "prompt_v1": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 81.2,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 28.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v2": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 78.8,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v3": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 75.2,
          "avg_exec_RAM_usage": 13952.0,
          "avg_exec_execution_time_ms": 40.0,
          "avg_exec_regressionTestPassed": 100.0
        },
        "prompt_v4": {
          "exec_quantity": 5,
          "successfully_exec_quantity": 5,
          "language": "python",
          "avg_exec_CPU_usage": 80.0,
          "avg_exec_RAM_usage": 13900.8,
          "avg_exec_execution_time_ms": 32.0,
          "avg_exec_regressionTestPassed": 100.0
        }
      }
    },
    "improvements_data": {
      "openAI": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -0.4914004914004809,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -23.076923076923077,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 3.4398034398034536,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -38.46153846153847,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 7.125307125307138,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -53.84615384615385,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 2.948402948402955,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -23.076923076923077,
          "regressionTestPassed": -0.0
        }
      },
      "gemini": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 1.2285012285012284,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -15.384615384615385,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -1.719901719901709,
          "RAM_usage": 0.3676470588235216,
          "execution_time_ms": 7.6923076923076925,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -3.6855036855036856,
          "RAM_usage": 0.0,
          "execution_time_ms": 7.6923076923076925,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": -1.4742014742014602,
          "RAM_usage": -0.36764705882353466,
          "execution_time_ms": 0.0,
          "regressionTestPassed": -0.0
        }
      },
      "claude": {
        "prompt_v1": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 0.24570024570024918,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -7.6923076923076925,
          "regressionTestPassed": -0.0
        },
        "prompt_v2": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 3.1941031941032048,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -23.076923076923077,
          "regressionTestPassed": -0.0
        },
        "prompt_v3": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 7.61670761670762,
          "RAM_usage": -0.18382352941176733,
          "execution_time_ms": -53.84615384615385,
          "regressionTestPassed": -0.0
        },
        "prompt_v4": {
          "LLM_successfully_exec_quantity": 5,
          "LLM_exec_quantity": 5,
          "language": "python",
          "CPU_usage": 1.7199017199017268,
          "RAM_usage": 0.18382352941176733,
          "execution_time_ms": -23.076923076923077,
          "regressionTestPassed": -0.0
        }
      }
    }
  }
}
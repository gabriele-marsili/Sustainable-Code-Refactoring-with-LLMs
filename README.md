# Sustainable Code Refactoring with LLMs

## Progetto di Tesi - UniversitÃ  di Pisa

**Anno Accademico:** 2024/2025

---

## ğŸ“‹ Indice

- [Introduzione](#introduzione)
- [Obiettivo della Tesi](#obiettivo-della-tesi)
- [Architettura del Sistema](#architettura-del-sistema)
- [Struttura della Directory](#struttura-della-directory)
- [Workflow Completo](#workflow-completo)
- [Stato del Progetto](#stato-del-progetto)
- [Quick Start](#quick-start)
- [Requisiti](#requisiti)
- [Comandi Principali](#comandi-principali)

---

## ğŸ¯ Introduzione

Questo progetto di ricerca esplora l'utilizzo di **Large Language Models (LLMs)** per il **refactoring automatico di codice** con focus sulla **sostenibilitÃ  computazionale**. L'obiettivo Ã¨ valutare se gli LLM possono generare codice ottimizzato che riduce:
- âš¡ Consumo energetico (CPU usage)
- ğŸ’¾ Utilizzo di memoria (RAM usage)
- â±ï¸ Tempo di esecuzione (execution time)

mantenendo la **correttezza funzionale** (test pass rate).

---

## ğŸ“ Obiettivo della Tesi

### Domanda di Ricerca Principale
**"Possono i Large Language Models generare automaticamente refactoring di codice che migliorano le metriche di sostenibilitÃ  senza compromettere la correttezza funzionale?"**

### Sotto-Obiettivi
1. **Dataset Creation:** Creare un dataset di coppie codice-test da repository Exercism
2. **LLM-Based Refactoring:** Generare versioni ottimizzate usando prompt engineering
3. **Metrics Collection:** Misurare CPU, RAM, tempo di esecuzione, test pass rate
4. **Comparative Analysis:** Confrontare baseline vs versioni LLM-generate
5. **Pattern Identification:** Identificare pattern di miglioramento per linguaggio e modello

---

## ğŸ—ï¸ Architettura del Sistema

```
PIPELINE COMPLETA
=================
Dataset Creation â†’ Clustering â†’ LLM Generation â†’ Docker Execution â†’ Metrics Analysis â†’ Unified Analyzer
```

---

## ğŸ“‚ Struttura della Directory

```
src/
â”œâ”€â”€ dataset/                      # Codice originale da Exercism (8 linguaggi)
â”œâ”€â”€ clusters/                     # Cluster organizzati per esercizio
â”œâ”€â”€ prompts/                      # Template prompt (v1, v2, v3, v4)
â”œâ”€â”€ out_improvements_metadata/    # Codice generato da LLM
â”œâ”€â”€ docker/                       # Dockerfiles per ogni linguaggio
â”œâ”€â”€ execution_outputs/            # Risultati esecuzioni JSON
â”œâ”€â”€ execution_reports/            # Report human-readable
â”œâ”€â”€ metrics/                      # Analisi metriche e visualizzazioni
â”œâ”€â”€ unified_analyzer/             # â­ MODULO UNIFICATO ANALISI ERRORI
â”œâ”€â”€ debug_tools/                  # Tool per debugging manuale
â”œâ”€â”€ utility_dir/                  # Utility condivise
â”œâ”€â”€ old/                          # Codice deprecato (post-refactoring)
â”œâ”€â”€ main.py                       # Entry point principale
â””â”€â”€ requirements.txt              # Dipendenze Python
```

Vedi [CLAUDE.md](CLAUDE.md) per documentazione dettagliata architettura.

---

## ğŸ”„ Workflow Completo

### 1. Dataset Creation
```bash
python src/main.py --add-sources -l python java typescript
python src/main.py --create-focused-cluster
```

### 2. LLM Generation
```bash
cd src/LLMs_generator_engine
python llm_generator.py --cluster-name two-sum --models openai claude gemini
```

### 3. Test Execution
```bash
cd src/run_tests_on_clusters
python run_tests_on_cluster.py --cluster-name two-sum --num-executions 5
```

### 4. Metrics Analysis
```bash
cd src/metrics
python main_exec_metrics_analysis.py
```

### 5. Unified Analysis
```bash
cd src
python -m unified_analyzer analyze --clusters all --modes all --root-cause --export json markdown
```

---

## ğŸ“Š Stato del Progetto

### âœ… Completato

- âœ… **Dataset Creation:** 8 linguaggi, ~150+ cluster, ~5000+ entry
- âœ… **LLM Integration:** OpenAI, Anthropic, Google - 4 prompt versions
- âœ… **Execution Infrastructure:** Docker containers, metrics collection
- âœ… **Metrics Analysis:** 4 obiettivi statistici + visualizations
- âœ… **Unified Analyzer:** Anomaly detection, root cause, auto-fixing

### ğŸš§ In Progress

- ğŸ”¨ CLI Unificato per workflow orchestration
- ğŸ”¨ Orchestration Layer completo
- ğŸ”¨ Cluster Rerunner per outlier handling

---

## ğŸš€ Quick Start

```bash
# Installazione
git clone [repository-url]
cd Sustainable-Code-Refactoring-with-LLMs
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Configurazione
cd src
cp .env.example .env  # Edit con le tue API keys

# Test rapido
cd run_tests_on_clusters
python run_tests_on_cluster.py --cluster-name blank --num-executions 1
```

---

## ğŸ“¦ Requisiti

- Python 3.9+
- Docker Desktop
- API Keys: OpenAI, Anthropic, Google Gemini

---

## ğŸ’» Comandi Principali

```bash
# Dataset
python src/main.py --statistics
python src/main.py --analysis --charts

# Unified Analyzer
python -m unified_analyzer analyze --help
python -m unified_analyzer validate --help
python -m unified_analyzer workflow --full

# Metrics
cd src/metrics
python main_exec_metrics_analysis.py
```

---

## ğŸ“š Documentazione

- [CLAUDE.md](CLAUDE.md) - Documentazione completa architettura
- [src/unified_analyzer/README.md](src/unified_analyzer/README.md) - Unified Analyzer API
- [src/metrics/README_exec_metrics.md](src/metrics/README_exec_metrics.md) - Metrics analysis

---

**Ultima modifica:** 2025-10-28  
**Versione:** 2.0.0 (Post-Refactoring Unified Analyzer)
